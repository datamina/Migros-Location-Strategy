{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad26e89-0c00-44e4-bdd0-3d3a10c9ebf4",
   "metadata": {},
   "source": [
    "## web scrapping the info from googlemaps\n",
    "- I commented the other cantons just to try the Canton de Vaud to check if it worked after getting the over query limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884321f-9d1a-4dca-aa47-f609a52a5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "class Shops:\n",
    "    def __init__(self, shop):\n",
    "        self.shop = shop\n",
    "        \n",
    "    api_key = json.load(open(\"googlemaps_key.json\"))[\"api_key\"]\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
    "\n",
    "    def get_shops_per_canton(self):\n",
    "\n",
    "        # List copy pasted from pgeocode (jobs.ch exercise)\n",
    "        kantons = ['Canton de Vaud']\n",
    "        \"\"\"\n",
    "        , 'Genève', 'Canton de Fribourg',\n",
    "            'Canton de Berne', 'Canton du Valais', 'Neuchâtel', 'Jura',\n",
    "            'Kanton Solothurn', 'Kanton Basel-Landschaft',\n",
    "            'Kanton Basel-Stadt', 'Kanton Aargau', 'Kanton Luzern',\n",
    "            'Kanton Nidwalden', 'Kanton Obwalden', 'Kanton Zug', 'Kanton Uri',\n",
    "            'Kanton Schwyz', 'Ticino', 'Kanton Graubünden',\n",
    "            'Kanton St. Gallen', 'Kanton Zürich', 'Kanton Schaffhausen',\n",
    "            'Kanton Thurgau', 'Kanton Glarus', 'Kanton Appenzell Ausserrhoden',\n",
    "            'Kanton Appenzell Innerrhoden']\n",
    "        \"\"\"\n",
    "\n",
    "        for canton in kantons:\n",
    "            canton_stores = []\n",
    "\n",
    "            params = {\n",
    "                \"query\": f\"{self.shop} in {canton}\",\n",
    "                \"key\": Shops.api_key\n",
    "        }\n",
    "            i=0\n",
    "\n",
    "            while i <= 20:\n",
    "                req = requests.get(Shops.url, params=params)\n",
    "                data = req.json()\n",
    "                print(f\"Response for {canton}: {data.get('status')}\")\n",
    "\n",
    "                # Add results\n",
    "                if \"results\" in data:\n",
    "                    canton_stores.extend(data[\"results\"]) #not using append or will nest results\n",
    "\n",
    "                # Check for next page token\n",
    "                next_page_token = data.get(\"next_page_token\")\n",
    "                if not next_page_token:\n",
    "                    break \n",
    "\n",
    "                # Update params for next request\n",
    "                params[\"pagetoken\"] = next_page_token\n",
    "\n",
    "                time.sleep(2)\n",
    "\n",
    "                i+=1\n",
    "\n",
    "            # Saving into JSON\n",
    "            with open(f\"{self.shop}_stores_in_{canton}.json\", 'w') as f:\n",
    "                json.dump(canton_stores, f, indent=4)\n",
    "\n",
    "        print(f\"Total results: {len(canton_stores)}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7393b9-16d0-4743-a1de-1c7e7c596a11",
   "metadata": {},
   "source": [
    "## calling the instances to create the files per canton for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f6727-3492-4dd0-9851-1829d8794624",
   "metadata": {},
   "outputs": [],
   "source": [
    "migros_instance = Shops(\"Migros\")\n",
    "migros_instance.get_shops_per_canton()\n",
    "\n",
    "\"\"\"\n",
    "coop_instance = Shops(\"Coop\")\n",
    "coop_instance.get_shops_per_canton()\n",
    "\n",
    "aldi_instance = Shops(\"Aldi\")\n",
    "aldi_instance.get_shops_per_canton()\n",
    "\n",
    "lidl_instance = Shops(\"Lidl\")\n",
    "lidl_instance.get_shops_per_canton()\n",
    "\n",
    "denner_instance = Shops(\"Denner\")\n",
    "denner_instance.get_shops_per_canton()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3f3cd-513b-4815-8b2a-c4580192e8ff",
   "metadata": {},
   "source": [
    "## The part where I concatenate and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789173ed-8262-4fd0-b1db-7c05f3bbc314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "######### prep list with all files names\n",
    "\n",
    "def list_of_files(folder_name):\n",
    "\n",
    "    file_list = glob.glob(f\"./data/{folder_name}/*.json\")\n",
    "    file_list = [os.path.basename(file) for file in file_list]\n",
    "    return file_list\n",
    "\n",
    "\n",
    "######### concat_and_clean\n",
    "\n",
    "def concat_and_clean(shop_name):\n",
    "\n",
    "    def list_of_files(shop_name):\n",
    "\n",
    "        file_list = glob.glob(f\"./data/{shop_name}/*.json\")\n",
    "        file_list = [os.path.basename(file) for file in file_list]\n",
    "        return file_list\n",
    "    \n",
    "    file_list = list_of_files(shop_name)\n",
    "    \n",
    "    all_data = pd.DataFrame()       # empty df to be filled\n",
    "\n",
    "    for file_name in file_list:         #load content into DFs\n",
    "        with open(f\"./data/{shop_name}/{file_name}\", \"r\", encoding=\"utf-8\") as file:      \n",
    "            data = json.load(file)\n",
    "\n",
    "        # Convert to a DF and concat\n",
    "        df = pd.DataFrame(data)\n",
    "        all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "    # clean\n",
    "    all_data = all_data.drop(columns = ['icon','icon_background_color','icon_mask_base_uri','photos','reference','place_id','plus_code','opening_hours','business_status'])\n",
    "    all_data[\"postal_code\"] = all_data[\"formatted_address\"].str.extract(r'(\\b\\d{4}\\b)')\n",
    "    all_data[\"city\"] = all_data[\"formatted_address\"].str.extract(r'\\b\\d{4}\\b\\s([\\w-]+)')\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "migros_all_cleaned = concat_and_clean('Migros')\n",
    "print(migros_all_cleaned.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
